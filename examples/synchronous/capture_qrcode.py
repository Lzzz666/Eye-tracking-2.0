import sys
import os
import time
import csv
import threading
import numpy as np
import cv2  # OpenCV
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from matplotlib.gridspec import GridSpec
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from pyzbar.pyzbar import decode
from utils.server_info import get_ip_and_port
from ganzin.sol_sdk.synchronous.models import StreamingMode
from ganzin.sol_sdk.synchronous.sync_client import SyncClient

# ------------- åˆå§‹åŒ– -------------
data_buffer = {"x": [], "y": [], "z": []}
buffer_size = 500  

address, port = get_ip_and_port()
sc = SyncClient(address, port)
th = sc.create_streaming_thread(StreamingMode.GAZE_SCENE_EYES)  # å•Ÿç”¨çœ¼ç› & å ´æ™¯å½±åƒ
th.start()

# å½±åƒåˆå§‹åŒ–
left_eye_img = np.zeros((100, 100, 3), dtype=np.uint8)  # é»‘è‰²å½±åƒ
right_eye_img = np.zeros((100, 100, 3), dtype=np.uint8)
scene_img = np.zeros((480, 640, 3), dtype=np.uint8)
cv2.namedWindow("Gaze Tracking View", 0)  # å…è¨±èª¿æ•´è¦–çª—å¤§å°
cv2.resizeWindow("Gaze Tracking View", 1200, 900)  # è¨­ç½®è¦–çª—ç‚º1200x900
final_image = np.zeros((480, 640, 3), dtype=np.uint8)  # é è¨­ä¸€å€‹ç©ºçš„å½±åƒ

recording = False  # æ¨™è¨˜æ˜¯å¦æ­£åœ¨éŒ„è£½
video_writer = None  # ç”¨ä¾†éŒ„è£½å½±ç‰‡çš„ VideoWriter
csv_file = None
csv_writer = None
output_dir = None


def create_output_dir():
    """å»ºç«‹ä»¥ç•¶å‰æ™‚é–“ç‚ºåç¨±çš„è³‡æ–™å¤¾"""
    timestamp = time.strftime("%Y%m%d_%H%M%S")  
    directory = f"records/{timestamp}"
    os.makedirs(directory, exist_ok=True)
    return directory

def stack_eye_images(left_eye: np.ndarray, right_eye: np.ndarray, scene_img: np.ndarray) -> np.ndarray:
    """
    å°‡å·¦çœ¼å’Œå³çœ¼å½±åƒå‚ç›´æ’åˆ—ï¼Œä¸¦æ”¾ç½®æ–¼å ´æ™¯å½±åƒçš„å·¦å´
    :param left_eye: å·¦çœ¼å½±åƒ
    :param right_eye: å³çœ¼å½±åƒ
    :param scene_img: å ´æ™¯å½±åƒ
    :return: åˆä½µå¾Œçš„å½±åƒ
    """
    # èª¿æ•´å·¦å³çœ¼å½±åƒå¤§å°ï¼Œä¿æŒæ¯”ä¾‹
    eye_height = max(left_eye.shape[0], right_eye.shape[0])
    left_eye_resized = cv2.resize(left_eye, (int(left_eye.shape[1] * eye_height / left_eye.shape[0]), eye_height))
    right_eye_resized = cv2.resize(right_eye, (int(right_eye.shape[1] * eye_height / right_eye.shape[0]), eye_height))

    # çœ¼éƒ¨å½±åƒå‚ç›´åˆä½µ
    eye_stack = np.vstack((left_eye_resized, right_eye_resized))

    # ç¢ºä¿èˆ‡å ´æ™¯å½±åƒçš„é«˜åº¦ä¸€è‡´
    scene_height = scene_img.shape[0]
    if eye_stack.shape[0] < scene_height:
        top_pad = (scene_height - eye_stack.shape[0]) // 2
        bottom_pad = scene_height - eye_stack.shape[0] - top_pad
        final_eye_stack = cv2.copyMakeBorder(eye_stack, top_pad, bottom_pad, 0, 0, cv2.BORDER_CONSTANT, value=[0, 0, 0])
    else:
        final_eye_stack = cv2.resize(eye_stack, (eye_stack.shape[1], scene_height))  # åªæœ‰è¶…éæ™‚æ‰ç¸®å°

    stacked_image = np.hstack((final_eye_stack, scene_img))

    return stacked_image

# æ¨¡æ“¬æŒ‰éˆ•åŠŸèƒ½
def mouse_callback(event, x, y, flags, param):
    global recording, video_writer, final_image, csv_file, csv_writer, output_dir  # âœ… åŠ å…¥ csv_writer

    button_x, button_y, button_w, button_h = 0, 0, 150, 50  

    if event == cv2.EVENT_LBUTTONDOWN:
        if button_x <= x <= button_x + button_w and button_y <= y <= button_y + button_h:
            recording = not recording  
            print(f"Recording started: {recording}")

            if recording:
                output_dir = create_output_dir()
                cv2.putText(final_image, 'Recording...', (button_x + 10, button_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
                
                video_writer = cv2.VideoWriter(f'{output_dir}/recording.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 15, (final_image.shape[1], final_image.shape[0]))

                csv_filename = os.path.join(output_dir, "data.csv")
                csv_file = open(csv_filename, mode='w', newline='', encoding='utf-8')  
                csv_writer = csv.writer(csv_file)  # âœ… åˆå§‹åŒ– csv_writer
                csv_writer.writerow(["Timestamp", "Gaze X", "Gaze Y", "Gaze Z"])
                print(f"ğŸ”´ é–‹å§‹éŒ„è£½: {output_dir}")

            else:
                cv2.putText(final_image, 'Recording Stopped', (button_x + 10, button_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
                
                video_writer.release()
                
                if csv_file:
                    csv_file.close()
                    csv_file = None
                    csv_writer = None  # âœ… æ¸…é™¤ csv_writerï¼Œé¿å…éŒ¯èª¤
                    print(f"ğŸ›‘ éŒ„è£½çµæŸï¼Œæª”æ¡ˆå­˜æ”¾æ–¼: {output_dir}")

# è¨­ç½®æ»‘é¼ äº‹ä»¶å›èª¿å‡½æ•¸
cv2.setMouseCallback("Gaze Tracking View", mouse_callback)

# ç•«å‡ºæŒ‰éˆ•
def draw_button(frame):
    button_x, button_y, button_w, button_h = 0, 0, 150, 50  # æŒ‰éˆ•çš„ä½ç½®å’Œå¤§å°
    button_color = (0, 255, 0) if recording else (0, 0, 255)  # æ ¹æ“šéŒ„è£½ç‹€æ…‹è¨­å®šé¡è‰²
    cv2.rectangle(frame, (button_x, button_y), (button_x + button_w, button_y + button_h), button_color, -1)  # ç¹ªè£½æŒ‰éˆ•èƒŒæ™¯
    cv2.putText(frame, "Start/Stop Recording", (button_x + 10, button_y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)  # æŒ‰éˆ•æ–‡æœ¬

# ------------- QR Code æƒæ -------------
def scan_qrcode(image: np.ndarray):
    """ å˜—è©¦æƒæå½±åƒä¸­çš„ QR Codeï¼Œä¸¦è¿”å›å…§å®¹ """
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # è½‰æ›ç‚ºç°éš
    detector = cv2.QRCodeDetector()  # OpenCV å…§å»º QR Code æƒæå™¨
    data, bbox, _ = detector.detectAndDecode(gray)

    if data:  # å¦‚æœåµæ¸¬åˆ° QR Code
        return data

    # ä½¿ç”¨ pyzbar å˜—è©¦è§£ç¢¼
    decoded_objects = decode(gray)
    for obj in decoded_objects:
        return obj.data.decode("utf-8")  # è§£æ QR Code å…§å®¹

    return None  # æ²’æœ‰åµæ¸¬åˆ° QR Code
# ------------- æ›´æ–°æ•¸æ“š -------------
def update_data():
    global data_buffer, left_eye_img, right_eye_img, scene_img, final_image, video_writer, csv_writer, csv_file 
    try:
        while True:
            gazes = sc.get_gazes_from_streaming(timeout=5.0)
            scene_frames = sc.get_scene_frames_from_streaming(timeout=5.0)
            left_eye_frames = sc.get_left_eye_frames_from_streaming(timeout=5.0)
            right_eye_frames = sc.get_right_eye_frames_from_streaming(timeout=5.0)

            # æ›´æ–° gaze æ•¸æ“š
            for gaze in gazes:
                if gaze.combined.gaze_3d.validity:
                    x, y, z = gaze.combined.gaze_3d.x, gaze.combined.gaze_3d.y, gaze.combined.gaze_3d.z
                    timestamp = time.time()

                    if len(data_buffer["x"]) >= buffer_size:
                        data_buffer["x"].pop(0)
                        data_buffer["y"].pop(0)
                        data_buffer["z"].pop(0)
                    data_buffer["x"].append(x)
                    data_buffer["y"].append(y)
                    data_buffer["z"].append(z)

                    # ğŸš€ æ–°å¢å¯«å…¥ CSV
                    if recording:
                        if csv_writer is None:  # ğŸ”¥ ç¢ºä¿ csv_writer ä¸ç‚º None
                            print("âš ï¸ éŒ¯èª¤: csv_writer å°šæœªåˆå§‹åŒ–ï¼")
                        else:
                            csv_writer.writerow([timestamp, x, y, z])  # âœ… å¯«å…¥æ™‚é–“æˆ³èˆ‡ gaze æ•¸æ“š
                            csv_file.flush()  # ğŸ”¥ ç«‹å³å¯«å…¥æ–‡ä»¶ï¼Œé˜²æ­¢æ„å¤–ä¸Ÿå¤±æ•¸æ“š

            # æ›´æ–°å½±åƒ
            if scene_frames:
                scene_img = scene_frames[-1].get_buffer()

            # æ“·å–å½±åƒä¸­å¿ƒéƒ¨åˆ†ï¼ˆå‡è¨­ QR Code åœ¨ç•«é¢ä¸­å¤®ï¼‰
            h, w, _ = scene_img.shape
            center_crop = scene_img[h//4:3*h//4, w//4:3*w//4]  # å–ç•«é¢ä¸­é–“ 50% å€åŸŸ

            # å˜—è©¦æƒæ QR Code
            qr_result = scan_qrcode(center_crop)
            if qr_result:
                print(f"ğŸ“· QR Code Detected: {qr_result}")

            if left_eye_frames:
                left_eye_img = left_eye_frames[-1].get_buffer()
            if right_eye_frames:
                right_eye_img = right_eye_frames[-1].get_buffer()

            # åˆä½µå½±åƒï¼ˆçœ¼ç›å½±åƒæ”¾å·¦å´ï¼‰
            final_image = stack_eye_images(left_eye_img, right_eye_img, scene_img)

            # ç•«å‡ºæŒ‰éˆ•
            draw_button(final_image)

            # é¡¯ç¤ºå½±åƒ
            if recording and video_writer:
                video_writer.write(final_image)  # éŒ„è£½å½±åƒ

            cv2.imshow("Gaze Tracking View", final_image)

            # æŒ‰ä¸‹ Q çµæŸ
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break

            time.sleep(0.05)
    except KeyboardInterrupt:
        print("ğŸ”´ æ¸¬è©¦å·²ä¸­æ–·")
    finally:
        print("ğŸ›‘ åœæ­¢ä¸²æµ")
        th.cancel()
        th.join()
        cv2.destroyAllWindows()


threading.Thread(target=update_data, daemon=True).start()

# ------------- è¨­å®š Matplotlib -------------
fig = plt.figure(figsize=(8, 6))
fig.suptitle("Real-time Gaze Tracking")

gs = GridSpec(2, 1, height_ratios=[2, 1])

# XY è»Œè·¡åœ–
ax_xy = fig.add_subplot(gs[0, 0])
ax_xy.set_title("Gaze XY Trajectory")
ax_xy.set_xlim(-1000, 1000)
ax_xy.set_ylim(-1000, 1000)
ax_xy.set_xlabel("Gaze X (mm)")
ax_xy.set_ylabel("Gaze Y (mm)")
ax_xy.grid()
xy_line, = ax_xy.plot([], [], 'bo-', markersize=3, alpha=0.5)

# Z è»¸æ³¢å½¢åœ–
ax_z = fig.add_subplot(gs[1, 0])
ax_z.set_xlim(0, buffer_size)
ax_z.set_ylim(0, 1500)
ax_z.set_ylabel("Gaze Z (mm)")
ax_z.set_title("Gaze Z Waveform")
ax_z.grid()
z_line, = ax_z.plot([], [], 'b-', label="Gaze Z")
ax_z.set_xlabel("Time Steps")

def update_plot(frame):
    xy_line.set_data(data_buffer["x"], data_buffer["y"])
    z_line.set_data(range(len(data_buffer["z"])), data_buffer["z"])
    return [xy_line, z_line]
ani = animation.FuncAnimation(fig, update_plot, interval=30, blit=True, cache_frame_data=False) 

try:
    plt.show(block=False)
    plt.show()
except KeyboardInterrupt:
    print("User interrupted. Exiting...")
    plt.close('all')

